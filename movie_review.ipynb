{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_review.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8RT20Evbz/iKdQkVAs3+9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyXRHEaw0F5-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoJU7l95_By6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = keras.datasets.imdb\n",
        "\n",
        "(train_data, train_labels),(test_data, test_labels) = data.load_data(num_words=10000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Urj9VCtK_RZx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_data[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxXjORav_dCA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = data.get_word_index()\n",
        "\n",
        "word_index = {k : v+3 for k, v in word_index.items()}\n",
        "\n",
        "word_index['<PAD>']= 0\n",
        "word_index['<START>']= 1\n",
        "word_index['<UNK>']= 2\n",
        "word_index['<UNUSED>']= 3\n",
        "\n",
        "reverse_word_index = dict([(value, key) for key, value in word_index.items()])\n",
        "\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, maxlen=250, padding = 'post', value=word_index['<PAD>'])\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, maxlen=250, padding='post', value=word_index['<PAD>'])\n",
        "\n",
        "\n",
        "\n",
        "def decode_review(text):\n",
        "   return \" \".join([reverse_word_index.get(i, \"?\") for i in text]) \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BG7R97GYBHQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(decode_review(test_data[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZTusPl7ChZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(test_data[1]), len(test_data[2]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyUljqvwCNzV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGDaunHoB9k9",
        "colab_type": "text"
      },
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yx0_z5RSCAbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = keras.Sequential()\n",
        "# model.add(keras.layers.Embedding(880000, 16))\n",
        "# model.add(keras.layers.GlobalAveragePooling1D())\n",
        "# model.add(keras.layers.Dense(16, activation='relu'))\n",
        "# model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXUPIhSXcHbp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "aa9d6fec-61e7-43d3-9065-3441bbb8a0a5"
      },
      "source": [
        "# model.compile(optimizer='adam', loss = \"binary_crossentropy\", metrics=['accuracy'])\n",
        "# x_val = train_data[:10000]\n",
        "# x_train = train_data[:10000]\n",
        "\n",
        "# y_val = train_labels[:10000]\n",
        "# y_train = train_labels[:10000]\n",
        "\n",
        "# fitmodel = model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)\n",
        "# result = model.evaluate(test_data, test_labels)\n",
        "# print(result)\n",
        "# model.save(\"model.h5\")\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "20/20 [==============================] - 3s 174ms/step - loss: 0.6925 - accuracy: 0.5902 - val_loss: 0.6910 - val_accuracy: 0.6636\n",
            "Epoch 2/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.6891 - accuracy: 0.6296 - val_loss: 0.6865 - val_accuracy: 0.6591\n",
            "Epoch 3/40\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.6837 - accuracy: 0.7189 - val_loss: 0.6795 - val_accuracy: 0.6995\n",
            "Epoch 4/40\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.6752 - accuracy: 0.7166 - val_loss: 0.6689 - val_accuracy: 0.7692\n",
            "Epoch 5/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.6627 - accuracy: 0.7815 - val_loss: 0.6539 - val_accuracy: 0.7808\n",
            "Epoch 6/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.6456 - accuracy: 0.7864 - val_loss: 0.6343 - val_accuracy: 0.7967\n",
            "Epoch 7/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.6239 - accuracy: 0.8027 - val_loss: 0.6101 - val_accuracy: 0.8126\n",
            "Epoch 8/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.5983 - accuracy: 0.8178 - val_loss: 0.5821 - val_accuracy: 0.8334\n",
            "Epoch 9/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.5688 - accuracy: 0.8319 - val_loss: 0.5514 - val_accuracy: 0.8439\n",
            "Epoch 10/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.5370 - accuracy: 0.8441 - val_loss: 0.5182 - val_accuracy: 0.8527\n",
            "Epoch 11/40\n",
            "20/20 [==============================] - 3s 155ms/step - loss: 0.5042 - accuracy: 0.8562 - val_loss: 0.4855 - val_accuracy: 0.8556\n",
            "Epoch 12/40\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.4707 - accuracy: 0.8678 - val_loss: 0.4523 - val_accuracy: 0.8739\n",
            "Epoch 13/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.4391 - accuracy: 0.8766 - val_loss: 0.4219 - val_accuracy: 0.8814\n",
            "Epoch 14/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.4097 - accuracy: 0.8840 - val_loss: 0.3939 - val_accuracy: 0.8901\n",
            "Epoch 15/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.3826 - accuracy: 0.8927 - val_loss: 0.3690 - val_accuracy: 0.8912\n",
            "Epoch 16/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3586 - accuracy: 0.8966 - val_loss: 0.3461 - val_accuracy: 0.8975\n",
            "Epoch 17/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.3370 - accuracy: 0.9009 - val_loss: 0.3248 - val_accuracy: 0.9057\n",
            "Epoch 18/40\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.3171 - accuracy: 0.9074 - val_loss: 0.3066 - val_accuracy: 0.9102\n",
            "Epoch 19/40\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2998 - accuracy: 0.9113 - val_loss: 0.2899 - val_accuracy: 0.9133\n",
            "Epoch 20/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2843 - accuracy: 0.9147 - val_loss: 0.2760 - val_accuracy: 0.9166\n",
            "Epoch 21/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.2703 - accuracy: 0.9173 - val_loss: 0.2611 - val_accuracy: 0.9200\n",
            "Epoch 22/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2561 - accuracy: 0.9210 - val_loss: 0.2487 - val_accuracy: 0.9256\n",
            "Epoch 23/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2441 - accuracy: 0.9248 - val_loss: 0.2370 - val_accuracy: 0.9296\n",
            "Epoch 24/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2329 - accuracy: 0.9293 - val_loss: 0.2258 - val_accuracy: 0.9321\n",
            "Epoch 25/40\n",
            "20/20 [==============================] - 3s 160ms/step - loss: 0.2223 - accuracy: 0.9317 - val_loss: 0.2165 - val_accuracy: 0.9359\n",
            "Epoch 26/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.2127 - accuracy: 0.9359 - val_loss: 0.2064 - val_accuracy: 0.9388\n",
            "Epoch 27/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.2034 - accuracy: 0.9387 - val_loss: 0.1977 - val_accuracy: 0.9430\n",
            "Epoch 28/40\n",
            "20/20 [==============================] - 3s 152ms/step - loss: 0.1948 - accuracy: 0.9411 - val_loss: 0.1897 - val_accuracy: 0.9458\n",
            "Epoch 29/40\n",
            "20/20 [==============================] - 3s 154ms/step - loss: 0.1866 - accuracy: 0.9463 - val_loss: 0.1813 - val_accuracy: 0.9484\n",
            "Epoch 30/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.1789 - accuracy: 0.9486 - val_loss: 0.1737 - val_accuracy: 0.9510\n",
            "Epoch 31/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.1713 - accuracy: 0.9517 - val_loss: 0.1667 - val_accuracy: 0.9531\n",
            "Epoch 32/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.1653 - accuracy: 0.9531 - val_loss: 0.1597 - val_accuracy: 0.9552\n",
            "Epoch 33/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.1582 - accuracy: 0.9557 - val_loss: 0.1534 - val_accuracy: 0.9580\n",
            "Epoch 34/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.1522 - accuracy: 0.9584 - val_loss: 0.1473 - val_accuracy: 0.9604\n",
            "Epoch 35/40\n",
            "20/20 [==============================] - 3s 157ms/step - loss: 0.1457 - accuracy: 0.9601 - val_loss: 0.1420 - val_accuracy: 0.9607\n",
            "Epoch 36/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.1400 - accuracy: 0.9621 - val_loss: 0.1362 - val_accuracy: 0.9650\n",
            "Epoch 37/40\n",
            "20/20 [==============================] - 3s 158ms/step - loss: 0.1346 - accuracy: 0.9641 - val_loss: 0.1306 - val_accuracy: 0.9666\n",
            "Epoch 38/40\n",
            "20/20 [==============================] - 3s 159ms/step - loss: 0.1291 - accuracy: 0.9664 - val_loss: 0.1254 - val_accuracy: 0.9679\n",
            "Epoch 39/40\n",
            "20/20 [==============================] - 3s 156ms/step - loss: 0.1242 - accuracy: 0.9685 - val_loss: 0.1211 - val_accuracy: 0.9691\n",
            "Epoch 40/40\n",
            "20/20 [==============================] - 3s 153ms/step - loss: 0.1195 - accuracy: 0.9706 - val_loss: 0.1162 - val_accuracy: 0.9710\n",
            "782/782 [==============================] - 2s 3ms/step - loss: 0.3167 - accuracy: 0.8699\n",
            "[0.31667426228523254, 0.869920015335083]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyiBT86TFy34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# result = model.evaluate(test_data, test_labels)\n",
        "# print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8YcP9VaGEDz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_review = test_data[0]\n",
        "# predict = model.predict([test_review])\n",
        "# print(\"review : \")\n",
        "# print(decode_review(test_review))\n",
        "# print(\"actual : \" + str(test_labels[0]))\n",
        "# print(\"predicted : \" + str(predict[0]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfiNmfmFIVNp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.load_model(\"model.h5\")"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUd1W0MIMKrV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "6f72d342-7ab1-4351-99e0-1db4f6be17b0"
      },
      "source": [
        "def review_encode(s):\n",
        "  encoded = [1]\n",
        "  for word in s:\n",
        "    if word.lower() in word_index:\n",
        "      encoded.append(word_index[word.lower()])\n",
        "    else :\n",
        "      encoded.append(2)\n",
        "  return encoded\n",
        "\n",
        "\n",
        "with open(\"text.txt\") as f:\n",
        "  for line in f.readlines():\n",
        "    nline = line.replace(\",\", \"\").replace(\".\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\":\", \"\").replace(\"/\", \"\").replace(\"/n\", \"\").strip().split(\" \")\n",
        "    encode = review_encode(nline)\n",
        "    encode = keras.preprocessing.sequence.pad_sequences([encode], maxlen=250, padding = 'post', value=word_index['<PAD>'])\n",
        "    predict = model.predict(encode)\n",
        "\n",
        "    print(line)\n",
        "    print(encode)\n",
        "    print(predict[0])\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I'm not usually one to pay attention to Internet celebrities or web series. But I fairly recently discovered the Nostalgia Critic, and all I could think after watching a few of his reviews was, where has this guy been all my life? I could watch his videos for hours.The Nostalgia Critic is best known for ripping apart movies and television of the 1980s and '90s that he finds corny or otherwise badly written/acted/executed, but recently he's branched out into the 2000s or even something currently in theaters. Chances are, at some point he's going to take a big steaming dump on something you love, pointing out all of its flaws. Even so, I can't argue with most of the points he makes, especially if I'm in tears laughing. He's known to be very loud and profane, and I admit that sometimes he goes overboard with the screaming and hysterics. But I think he makes up for it with clever writing and editing. He's not just a guy yelling at a camera. A lot of thought and effort goes into making an NC episode, and there are plenty of behind the scenes videos to prove it. It also helps to know that the Critic is just a character that Doug plays and he's not really that angry in real life.Recent NC episodes have featured some sort of subplot with supporting characters, which fans seem to either love or hate. I personally find the subplots hit or miss. Sometimes they're funny and entertaining, and other times they just detract from the review. I think I will always prefer the older episodes with just Doug talking, but it's nice to see the chemistry between Doug and his Channel Awesome co-stars.The Critic offers more than just exaggerated bad reviews. Sometimes he'll positively review something, and his editorials and top 11 lists are entertaining and insightful. My personal favorite material of his outside of reviewing movies and TV shows are his commercial specials. It was a brilliant idea to review TV advertisements of the '80s and '90s. Watching the commercials for those products you begged your parents for feels just as nostalgic as watching your old favorite Saturday morning cartoons.To sum things up, I love this guy. He's hilarious, talented, intelligent, and just plain endearing. If I could spend a day making fun of laughably bad movies with anyone in the world, it'd be Doug Walker.\n",
            "\n",
            "[[  104    29   166    56    18    12    19  1096   487     5   802   240\n",
            "     24    43     6   232  4578    33     6   370     6   176     7   197\n",
            "      5   781   271    83   231    35 10738   390     5    50    26   958\n",
            "      7   496     4   139  3364     8  1970    12    12    82  1525     8\n",
            "    124    15     4  3857     9    43     6   109    15  7517   299     5\n",
            "    240    24    66    15  1612    11   147     2 10738   672    28  2561\n",
            "     49   432     7  3677    19   696   105    63   451   306     8   345\n",
            "    119    42   784    13  1276   169     4  4763   569    42   717   518\n",
            "    507   163     5   441     5    85   211    36    43  6206    39     4\n",
            "    733    13   104    13    80   210  2788     4   922   672    19    43\n",
            "   7517   662    21    45   327     8    67     4  1175   200  7517     5\n",
            "     27  1308  1190     2  3857  1580    53    74    43  3694    78   857\n",
            "    518  3872  5402   733   142     5    27     2     5   350  1502  8698\n",
            "     26   441     5  5944    61   965   514   819     7    27  1005     7\n",
            "   6695   102     5   248   287    26    27  2153 12399    12    16     6\n",
            "    530   326     8   733   248 11536     7     4  7423     5 14330   149\n",
            "      4  3837    18   148  7016    25 11595   129   846    18   764    43\n",
            "     17  4428    17   149   129   154   514  2324  1972     2  3040   183\n",
            "     56    13   119    14   232   240   642  1020  1089     5    43  1044\n",
            "   3308    48    13   100  1142     6   251   231   253     7  5006    78\n",
            "    102    19   259    11     4   182  9899    30  7517  4055]]\n",
            "[0.9942053]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDEqbNl1Qh7q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}